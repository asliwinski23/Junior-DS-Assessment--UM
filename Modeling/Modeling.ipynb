{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924bb314",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "906303e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stats\n",
    "from sklearn import preprocessing\n",
    "import plotly.express as px\n",
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c93e0",
   "metadata": {},
   "source": [
    "## 2. Import cleaned train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce16bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d989f67",
   "metadata": {},
   "source": [
    "## 3. Creating Functions for Modeling\n",
    "### 3a) Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a25f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split function with scaling\n",
    "def set_train_test_scaled(data, input_seed, pct_test, features, target):\n",
    "    \"\"\"Returns train_df (pd.DataFrame), test_df (pd.DataFrame) which are randomly split training and testing data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    data (pd.DataFrame) -- All the data, must include all features that you want to look at and also target.\n",
    "        Optionally, can include other random columns.\n",
    "    input_seed (int) -- seed for randomization.\n",
    "    pct_test (float) -- must be between 0 and 1 inclusive. The percent of data used for testing.\n",
    "    \"\"\"\n",
    "    train_df, test_df = train_test_split(\n",
    "        data,\n",
    "        test_size = pct_test, \n",
    "        random_state = input_seed\n",
    "    )\n",
    "    \n",
    "    train_y = train_df[target].reset_index(drop=True)\n",
    "    train_df = pd.DataFrame(MinMaxScaler().fit_transform(train_df[features]), columns = features)\n",
    "    train_df[target] = train_y\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1acab1",
   "metadata": {},
   "source": [
    "### 3b) Outline model stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932a5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_acc_stats(y_actual_test, y_pred_test, model_name, features):\n",
    "    \"\"\"Returns model_stats (pd.DataFrame) which contains performance data for the model.\n",
    "\n",
    "    Keyword arguments:\n",
    "    y_actual (pd.Series or numpy.ndarray) -- the actual y values.\n",
    "    y_pred (pd.Series or numpy.ndarray) -- the predicted y values.\n",
    "    model_name (str) -- what you want to call the model. it will be saved in a csv later.\n",
    "    features (list) -- list of the column names used in this model to create the predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # test metrics\n",
    "    test_accuracy = accuracy_score(y_actual_test, y_pred_test) # real y goes first, predicted y goes second\n",
    "    test_precision = precision_score(y_actual_test, y_pred_test)\n",
    "    test_recall = recall_score(y_actual_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_actual_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_actual_test, y_pred_test)\n",
    "\n",
    "    # make a dataframe with model results used to save results into a CSV\n",
    "    model_stats = pd.DataFrame( \n",
    "            {\n",
    "                'model_name':model_name, # this is the model type I testing\n",
    "                'features':[features], \n",
    "                'test_accuracy':test_accuracy,\n",
    "                'test_precision':test_precision,\n",
    "                'test_recall':test_recall,\n",
    "                'test_f1':test_f1,\n",
    "                'test_roc_auc':test_roc_auc\n",
    "            }\n",
    "    )\n",
    "    return model_stats\n",
    "\n",
    "# write stats to a csv\n",
    "def helper_write(stats, file_path):\n",
    "    try: # try means it will \"try\" the following code. if it results in an error, then it will stop and jump to except\n",
    "        df_results = pd.read_csv(file_path) # this returns an error if results.csv isn't an actual file. \n",
    "        # if there is df_results, then add new results to it.\n",
    "\n",
    "        df_results = pd.concat([df_results, stats])\n",
    "        df_results.to_csv(file_path, index=False)\n",
    "    except:\n",
    "        print(f'There is no CSV called {file_path}')\n",
    "        stats.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f873fca",
   "metadata": {},
   "source": [
    "### 3c) Outline how to evaluate model, for forward step feature selection, testing, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bf0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(input_name, input_model, training_data, testing_data, features, target):\n",
    "    \"\"\"Writes test results of a model using training and testing data with features and a target.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_name (str) -- what you want to call the model. it will be saved in a csv later.\n",
    "    input_model (sklearn model) -- model.\n",
    "    training_data (pd.DataFrame)\n",
    "    testing_data (pd.DataFrame)\n",
    "    features (list) -- list of the column names used in this model to create the predictions.\n",
    "    features (str) -- name of column that we want to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set training/test X/y\n",
    "    X_train = training_data[features]\n",
    "    y_train = training_data[target]\n",
    "    X_test = testing_data[features]\n",
    "    y_test = testing_data[target]\n",
    "    \n",
    "    # fit the model that was passed in\n",
    "    # model = input_model()\n",
    "    model = clone(input_model) #testing\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    # get predictions on the test data\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # generate stats (dataframe) of the accuracy, precision, recall, f1, and roc auc\n",
    "    stats = helper_acc_stats(\n",
    "        y_actual_test = y_test, \n",
    "        y_pred_test = y_test_pred,\n",
    "        model_name = input_name, \n",
    "        features = features,\n",
    "    )\n",
    "    # write the stats to a csv so we can look at\n",
    "    helper_write(stats = stats, file_path = 'results.csv')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22f034",
   "metadata": {},
   "source": [
    "### 3d) Feature Selection + Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79739842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection_scaled(model, data, all_feats, target, model_name):\n",
    "    \n",
    "    # set train/test split\n",
    "    train_df, test_df = set_train_test_scaled(data = data, input_seed = 1, pct_test = 0.2, features = all_feats, target=target)\n",
    "    \n",
    "    best_model_feats = [] # stores best model feats\n",
    "    for i in range(len(all_feats)):\n",
    "        \n",
    "        prop_feats = [] # proposed feats to add\n",
    "        best_model_roc_auc = -999999999999\n",
    "        \n",
    "        for c in all_feats:\n",
    "            # if the feat that we are considering adding is already in our current best model, then skip\n",
    "            if c in best_model_feats: \n",
    "                continue\n",
    "\n",
    "            # this is a list of the features we are going to test for this iteration\n",
    "            feats_to_test = best_model_feats.copy()\n",
    "            feats_to_test.append(c)\n",
    "\n",
    "            fitted_model = evaluate_model(model_name, model, train_df, test_df, feats_to_test, target)\n",
    "            \n",
    "            y_pred = fitted_model.predict(test_df[feats_to_test])\n",
    "            y_actual = test_df[target]\n",
    "\n",
    "            stats = helper_acc_stats(y_actual, y_pred, model_name, feats_to_test)\n",
    "            roc_auc_stat = stats.loc[0,'test_roc_auc']\n",
    "\n",
    "            if roc_auc_stat > best_model_roc_auc:\n",
    "\n",
    "                best_model_roc_auc = roc_auc_stat \n",
    "                prop_feats = feats_to_test\n",
    "                \n",
    "        best_model_feats = prop_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0195f52",
   "metadata": {},
   "source": [
    "## 4. Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce92007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define starting features\n",
    "def starting_features(data):\n",
    "    features = []\n",
    "    for i in data.columns:\n",
    "        if i != 'Loan_Status':\n",
    "            features.append(i)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74cdf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_features = starting_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "345d581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no CSV called results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression model\n",
    "forward_selection_scaled(LogisticRegression(), df, starting_features, 'Loan_Status', 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1c9ecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no CSV called results.csv\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13188\\3703130945.py\u001b[0m in \u001b[0;36mhelper_write\u001b[1;34m(stats, file_path)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdf_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mdf_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3551\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3552\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         )\n\u001b[1;32m-> 1180\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'results.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13188\\2044486470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mOf\u001b[0m \u001b[0mcourse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0muse\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlower\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mgradually\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mll\u001b[0m \u001b[0mnotice\u001b[0m \u001b[0mworse\u001b[0m \u001b[0mperformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m '''\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mforward_selection_scaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarting_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Loan_Status'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Random Forest Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13188\\2340176634.py\u001b[0m in \u001b[0;36mforward_selection_scaled\u001b[1;34m(model, data, all_feats, target, model_name)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mfeats_to_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mfitted_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeats_to_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats_to_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13188\\3959669318.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(input_name, input_model, training_data, testing_data, features, target)\u001b[0m\n\u001b[0;32m     33\u001b[0m     )\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# write the stats to a csv so we can look at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mhelper_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'results.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13188\\3703130945.py\u001b[0m in \u001b[0;36mhelper_write\u001b[1;34m(stats, file_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'There is no CSV called {file_path}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3549\u001b[0m         )\n\u001b[0;32m   3550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3551\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3552\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3553\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         )\n\u001b[1;32m-> 1180\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'results.csv'"
     ]
    }
   ],
   "source": [
    "# run random forest regression model\n",
    "'''\n",
    "You need a bit more than 8GB RAM for predicting 2 classes with 256 trees.\n",
    "Of course, you can use a lower number, but gradually you'll notice worse performance.\n",
    "'''\n",
    "forward_selection_scaled(RandomForestClassifier(n_estimators=256), df, starting_features, 'Loan_Status', 'Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613f3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
